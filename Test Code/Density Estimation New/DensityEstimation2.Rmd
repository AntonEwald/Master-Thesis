---
title: "DensityEstimation2"
author: "Anton Holm"
date: '2022-03-09'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(mvtnorm)
library(MASS)
library(dbscan)
library(foreach)
```

```{r, eval = FALSE}
#### Generates a GMM data sample ####
 # No need to run this code
source("..\\Generate_Data_Script.R")
gauss <- generate_data(n = 1500000, clusters = 6000, cellwidth = 11.6)
# saveRDS(gauss, file = "GMM_data.rdata")
######################################
```

```{r}
#### Load the saved data ####
GMM_data <- readRDS("GMM_data.rdata")
GMM_coordinates <- GMM_data[[1]]
True_density <- GMM_data[[2]]
True_rank <- rank(GMM_data[[2]])
mu <- GMM_data[[3]]

#Elements are d_ij
  #Adjacency_Matrix <- kNNdist(GMM_coordinates, k = 7, all = TRUE)
  #saveRDS(Adjacency_Matrix, file = "Adjacency_Matrix.rda")
Adjacency_Matrix <- readRDS("ADjacency_Matrix.rda")
##############################
```

```{r}
#### Density Estimation 1 ####
#Density = 1/sum_j(d_ij)
Density_Vector1 <- 1/rowSums(Adjacency_Matrix)
Ranks1 <- rank(Density_Vector1)

#Spearman Correlation Test
cor.test(True_rank, Ranks1, method = "spearman")
##############################
```

```{r}
#### Density Estimation 2 ####
# Density = 1/(1+sum_j(d_ij)^2)
Density_vector2 <- 1/(1 + rowSums(Adjacency_Matrix^2))
Ranks2 <- rank(Density_vector2)

cor.test(True_rank, Ranks2, method = "spearman")
##############################
```

```{r}
#### Gaussian Kernel Estimation ####
kernel <- function(x, h){
  1/(2*pi*h^2) * exp(-1/2 * (x/h)^2)
}

#Calculate euclidean distance to all k-nearest neighbors (list with each gene-type in the list)
knn_distance <- kNNdist(GMM_coordinates, k = 50, all = TRUE)

kde_dens <- kernel(knn_distance, h = 2.5) %>% 
  rowSums()
####################################
```



New code to run loop 6000 times
```{r}

Estimated_modes1 <- matrix(NA, nrow = 6000, ncol = 6)
Estimated_modes2 <- matrix(NA, nrow = 6000, ncol = 6)
Estimated_modes3 <- matrix(NA, nrow = 6000, ncol = 6)

for (i in 1:6000) {
  M <- cbind(1:nrow(GMM_coordinates), apply(GMM_coordinates, MARGIN = 1, FUN = function(x) sqrt(sum((x[]-mu[i,])^2))), Density_Vector1, Density_vector2, kde_dens)
  sub_M <- M[M[,2] < 3*sqrt(11.6), ]
  ordered <- sub_M[order(sub_M[,2], decreasing = FALSE), ] %>% 
    cbind(1:nrow(sub_M))
  Estimated_modes1[i, ] <- ordered[which.max(ordered[,3]), ]
  Estimated_modes2[i, ] <- ordered[which.max(ordered[,4]), ]
  Estimated_modes3[i, ] <- ordered[which.max(ordered[,5]), ]

  print(i)
}
```

Make the dataframe of all estimated modes + true modes + statistics
```{r}
Final_mode_df <- Estimated_modes1 %>% 
  as_tibble() %>% 
  dplyr::select(V1, V2, V6) %>% 
  rename(c("Datapoint ID" = V1, "Distance to mode" = V2, "KNN index" = V6)) %>% 
  mutate(Method = "Inverse Distance") %>% 
  add_row(`Datapoint ID` = Estimated_modes2[, 1], `Distance to mode` = Estimated_modes2[, 2], `KNN index` = Estimated_modes2[, 6], Method = "Stationary Distribution") %>% 
  add_row(`Datapoint ID` = Estimated_modes3[, 1], `Distance to mode` = Estimated_modes3[, 2], `KNN index` = Estimated_modes3[, 6], Method = "KDE") %>% 
  drop_na()

saveRDS(Final_mode_df, file = "Estimated_Modes_vs_True_Circular_Data.rdata")
```

```{r}

Estimated_vs_True <- readRDS("Estimated_Modes_vs_True_Circular_Data.rdata")
#Spatial distribution of estimated modes  
Estimated_vs_True %>% 
  ggplot(aes(x = `KNN index`, col = `Method`)) +
  geom_density() +
  labs(title = "Distribution of which k-NN of true mode is the estimated mode Estimation 1")

#Shows distribution of the distance of estimated mode to the true mode
Estimated_vs_True %>% 
  ggplot(aes(x = `Distance to mode`, col = Method)) +
  geom_density()
#####################################################################
```

Code to analyze result of the three methods estimated modes
```{r}
Estimated_Mode_Statistics <- Estimated_vs_True %>% 
  mutate(x = GMM_coordinates[`Datapoint ID`, 1],
         y = GMM_coordinates[`Datapoint ID`, 2],
         mu_x = rep(mu[, 1], 3),
         mu_y = rep(mu[, 2], 3)) %>% 
  mutate(diff_x = x-mu_x,
         diff_y = y-mu_y)


ggplot(Estimated_Mode_Statistics, aes(x = diff_x, y = diff_y, col = Method)) +
  geom_point()

Estimated_Mode_Statistics %>% 
  group_by(Method) %>% 
  summarise(x_bias = mean(diff_x))



#1-D Distribution of the x and y coordinates in true mode - estimated mode
#They are clearly gaussian

ggplot(Estimated_Mode_Statistics, aes(x = diff_x, col = Method)) +
  geom_density()

ggplot(Estimated_Mode_Statistics, aes(x = diff_y, col = Method)) +
  geom_density()
```


How does my gaussians look like?
```{r}
GMM_coordinates[1:243,] %>% 
  as_tibble() %>% 
  ggplot(aes(x = V1, y = V2)) + 
  geom_point()

sweep(GMM_coordinates[1:243,], 2, mu[1,]) %>% 
  as_tibble() %>% 
  colMeans()
```

In the loop that take too much memory: Only save the estimated mode each time, then I can run all 6000 probably!

Create a nicer pipeline for estimating densities.

What does the sigma mean, i.e. variance of estimated mode? How do we calculate them? What is the interpretation of them?

How do we find local maximums?

Try data with alternating covariance matrix and compare results.

On Christophers data: Try sctransform + clustering and no normalization + clustering and compare.


Check the distance between every true mode

Check bias and variance of the gaussians points
THink of it as taking each true mode at origin and see how the points gets distributed

For meeting:
  - How do we decide on k?
  - Show distribution of which k-NN was estimated as the mode
  - How do we apply the rank spatial preservence statistics in our case?

What I did last time:
  - I checked the distribution of which neighbor to the true modes is the estimated mode for 1/sum(d_ij)

Next:
  - Do the same for stationary distribution aswell