---
title: "Test Data"
author: "Anton Holm"
date: '2021-12-13'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(loomR)
library(tidyverse)
library(rhdf5)
library(MASS)
library(dbscan)
library(raster)
library(matrixStats)
# Sys.setenv(RETICULATE_PYTHON = "C:\\Users\\anton\\PycharmProjects\\HelloWorld\\venv\\Scripts\\python.exe")

library(reticulate)
Sys.setenv(RETICULATE_PYTHON="C:\\Users\\anton\\PycharmProjects\\pythonProject\\pythonProject\\MasterThesis\\venv\\Scripts\\python.exe") #True one
library(reticulate)
```

```{r}
################################ For cells ####################################################
#Read data and extract useful information
lfile <- connect(filename = "osmFISH.loom", mode = "r+")
gene_count <- lfile$matrix[,]
gene_names <- lfile$row.attrs$Gene[]
clusters <- lfile$col.attrs$ClusterID[]
x <- lfile$col.attrs$X[]
y <- lfile$col.attrs$Y[]
df <- as.data.frame(gene_count)
colnames(df) <- gene_names
cell_id <- lfile$col.attrs$CellID[]

#Spatial information of different cells
data <- df %>% 
  mutate(CellID = cell_id, Cluster = as.factor(clusters), x = x, y = y) %>% 
  dplyr::select(CellID, Cluster, x, y, everything())

data %>% 
  mutate(x = x/15.38, y = y/15.38) %>% 
  ggplot(aes(x = x, y = y, col = Cluster)) + 
  geom_point()
################################################################################################

mean_genes <- data %>% 
  dplyr::select(-c(CellID, Cluster, x, y)) %>% 
  rowSums() %>% 
  mean() 

sd <- data %>% 
  dplyr::select(-c(CellID, Cluster, x, y)) %>% 
  rowSums() %>% 
  sd()

data %>% group_by(Cluster) %>% summarise(tot = n())

data %>% 
  mutate(tot_gene = rowSums(.[5:37])) %>% 
  dplyr::select(Cluster, tot_gene) %>% 
  group_by(Cluster) %>% 
  summarise(mean = mean(tot_gene)) %>% 
  summarise(sd = sd(mean))

```

```{r}
########################################## Load data ###########################################
#Gaussian kernel width = h
kernel <- function(x, h){
  1/(2*pi*h^2) * exp(-1/2 * x/h^2)
}
#Number of different types of genes
gene_type_quant <- 1:39
#Proportions from data creator
pix_per_um <- 15.3846
um_per_pix <- 1/pix_per_um
#Load data of all genes
genes <- h5ls("osmFISHcoords.hdf5")
gene_names <- genes$name
#Genes as list of df
all_genes_df <- map(gene_names, ~as.data.frame(t(h5read("osmFISHcoords.hdf5", .x))) %>% mutate(gene = .x) %>% 
                      mutate(V1 = V1 * um_per_pix, V2 = V2 * um_per_pix))
#Genes in one df
genes_coords <- all_genes_df %>% 
  reduce(full_join, by = c("V1", "V2", "gene"))
#list of matrices with coordinates of genes
all_genes_matrix_unscaled <- map(gene_names, ~t(h5read("osmFISHcoords.hdf5", .x)))
all_genes_matrix <- lapply(all_genes_matrix_unscaled, function(x) x*um_per_pix) #
################################################################################################
```

```{r}
################################### Kernel Density Estimation ##################################
#Calculate euclidean distance to all k-nearest neighbors (list with each gene-type in the list)
knn_distance <- map(gene_type_quant, ~kNNdist(all_genes_matrix[[.x]], k = 50, all = TRUE))
#Apply kernel function and sum up distances
kernel_knn_dist <- map(gene_type_quant, ~kernel(knn_distance[[.x]], h = 2.5))
knn_kde <- map(gene_type_quant, ~rowSums(kernel_knn_dist[[.x]]))

#2 example plots of the density, first one fewer points, second many points
ggplot(as.data.frame(all_genes_matrix[[1]]), aes(x = V1, y = V2, alpha = knn_kde[[1]])) +
  geom_point()
ggplot(as.data.frame(all_genes_matrix[[2]]), aes(x = V1, y = V2, alpha = knn_kde[[2]])) +
  geom_point()
################################################################################################
```

```{r}
###################################### create vector field #####################################
# Extract largest x and y coordinate from the genes to create a grid/pixels
x_max <- max(do.call(rbind, lapply(all_genes_matrix, colMaxs))[,1])
y_max <- max(do.call(rbind, lapply(all_genes_matrix, colMaxs))[,2])
max_coord = max(x_max, y_max) #Use the maximum of both to create a square grid
#Create the grid (res 1 takes too much memory)
pixels <- raster(xmn = 0, xmx = max_coord, ymn = 0, ymx = max_coord, res = 4)

#Create Vector Field (list of df with pixel density of each gene) (From paper, each df is one picture with one gene type)
kde_genes_df <- map(gene_type_quant, ~mutate(all_genes_df[[.]], value = knn_kde[[.]]))
rast <- map(gene_type_quant, ~rasterize(kde_genes_df[[.]][,1:2], pixels, field = kde_genes_df[[.]][4], fun = sum))
vec_field <- map(gene_type_quant, ~getValues(rast[[.]]) %>% 
                   as.data.frame() %>% 
                   replace(is.na(.), 0))

#Need better way to rename column
for(i in gene_type_quant){
  names(vec_field[[i]])[1] <- gene_names[i]
}

#The complete vectorfield. Each column contains the KDE of every pixel of a gene (From paper, pictures are stacked)
full_vec_field <- do.call(cbind.data.frame, vec_field) %>% 
  mutate(total_kde = rowSums(.),
         x = rep(0:(dim(pixels)[2]-1), length.out = n()),
         y = rep(0:(dim(pixels)[1]-1),  each = dim(pixels)[2])) %>% 
  rowid_to_column("PixelID")

#Construct pixel matrix with kde values in each element of matrix to use for maximum_filter function for downsampling
kde_grid <- full_vec_field %>% 
  dplyr::select(x, y, total_kde) %>% 
  spread(key = x, value = total_kde) %>% 
  dplyr::select(-y) %>% 
  as.matrix()

save(kde_grid, file = "kdematrix.Rdata")
```


```{r}
#Testing and making sure kde and data match up with raster object


#plot of vec field (one plot per gene)
vec_field_plotted <- map(gene_type_quant, ~plot(rast[[.]]))

full_vec_field %>% 
  ggplot(aes(x = x, y = y)) +
  geom_raster(aes(fill = total_kde))

full_vec_field %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point( shape = ".")

full_vec_field %>% 
  arrange(desc(total_kde)) %>% 
  slice(1:30000) %>% 
  sample_n(size = 12000) %>% 
  ggplot(aes(x = x*pix_per_um, y = y*pix_per_um)) + 
  geom_point(size = 1) +
  scale_x_reverse()

vec_field[[36]] %>% 
  rowid_to_column() %>% 
  arrange(desc(Ttr_Hybridization13))

vec_field[[15]] %>% mutate(total_kde = rowSums(.),
         x = rep(0:(dim(pixels)[2]-1), length.out = n()),
         y = rep(0:(dim(pixels)[1]-1),  each = dim(pixels)[2])) %>% 
  filter(total_kde != 0) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point(size = 0.1, aes(alpha = total_kde)) +
  scale_y_reverse()
  
full_vec_field %>% 
  filter(total_kde != 0)
```

```{python}
### Downsampling using python function
from scipy import ndimage as ndi
import matplotlib.pyplot as plt
from skimage.feature import peak_local_max
from skimage import data, img_as_float


im = r.kde_grid
# image_max is the dilation of im with a size*size structuring element
image_max = ndi.maximum_filter(im, size=10)
```

```{r}
################################### Downsampled vectorfield ##################################

#Constructed using python code last chunk. Maximum filter picture
max_img <- py$image_max
max_img[max_img == 0] <- NA
  

#Construct local maximum vector field
local_maximum_vec_field <- full_vec_field %>% 
  filter(total_kde %in% max_img & total_kde > 0.04) %>%  # Keep pixels contained in max_img and larger than 0.04 (from their code)
  filter_at(vars(2:40), any_vars(. > 0.027)) %>% # Keep pixels with at least one gene higher density than 0.027 (from their code)
  filter(x < 350) #They removed part of the image using a mask. In practice, they chopped of part of the x-axis (the chopped part was used for testing stripping efficiency)
  
#Make the plot of local maximum vectors as they did in SSAM (at code)
local_maximum_vec_field %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(shape = ".") +
  xlim(900, 0) +
  ylim(0, 900)
##############################################################################################


```



Done last time: I figured out how they used the maximum filter (they dont use local peak max!!). I applied it on the vector field and got a similar result as in the paper (code part of SSAM). They chopped off part of the x-axis so I did the same.



They never use peak_local_max in the source code! They just make use of the maximum_filter.
  - Here is how their downsampling works: They use ndi.maximum_filter(size = 3). We have a pixel image with L1-norm density value at each pixel. If size = 3, then every pixel now gets the largest density value from any pixel that is at most 3 pixelsteps away from it. Then take your dataframe, filter away any pixel that does not have a total kde value contained in this maximum_filter matrix we get.
  - What does this really mean: We pick every pixel with the highest density conditioned on that the pixels needs to be at least "size" amount of steps away from eachothers. So if we have 2 high density pixels close to eachother, we only pick the pixel with the largest density.
  

From the code they specify width = 2080, height = 3380 um. Does this mean they have rectangles instead of squares as pixels? Is this good/bad?

Ask Mats and/or Chun: how the normalization works. It is called sctransform and based on biology and negative binomial. ( Hafemeister, C. & Satija, R. Normalization and variance stabilization of singlecell RNA-seq data using regularized negative binomial regression. Genome
Biol. 20, 296 (2019).)

Ask Chun: Will we use the MI estimation I(X, Y) as the KDE?

In paper by Kraskov. How do we implement a kernel? Is it the choice of mu(x,y)?

He mentioned using perplexity to get adaptive bandwidth. How does this work?

Different methods to use for boundary bias issues:
  - Smoothing Splines
  - Local likelihood density estimation (Dens Est Paper)
  - Local Linear Regression (Supervised Learning course material)

Also need to read about Smoothing Splines (See Supervised Learning prints sec 6.1-6.3)