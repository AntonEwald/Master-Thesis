---
title: "DensityEstimation2VaryingShape"
author: "Anton Holm"
date: '2022-03-19'
output: html_document
---

Here we generate GMM sample with varying shape of the cells.

```{r, eval = FALSE}
#### Load and plot data ####
source("..//Generate_GMM_Data.R")
data123 <- Generate_GMM_Data(c = 250, tissue_x = 400, tissue_y = 400, Cellwidth = 11.6, Mode = 3)
saveRDS(data123, "(DATA) n = 57.000, c = 250, tissue = 400, VS.rdata")
GMM_data_VS <- readRDS("(DATA) n = 57.000, c = 250, tissue = 400, VS.rdata") 
ggplot(data = NULL, aes(x = GMM_data_VS$Coordinates[,1], y = GMM_data_VS$Coordinates[,2], col = GMM_data_VS$Samples)) +
   geom_point() +
   guides(col = 'none')
data123$Coordinates %>% nrow()
```

Load all needed objects
```{r}
#### Load the saved data ####
GMM_coordinates_VS <- GMM_data_VS$Coordinates
True_density_VS <- GMM_data_VS$Density
mu_VS <- GMM_data_VS$Mu
GMM_sample_VS <- GMM_data_VS$Samples

#Elements are d_ij
Adjacency_Matrix_VS <- kNNdist(GMM_coordinates_VS, k = 7, all = TRUE)
##############################
```

Three different density estimators. 
$\rho_1 = \sum_{j=1}^k 1/d_{ij}$ where $d_{ij}$ is the euclidean distance between point i and its k nearest neighbors.
$\rho_2 = \sum_{j=1}^k 1/(1+d_{ij}^2)$
$\rho_3$ is the kernel density estimation used in SSAM paper, i.e. KDE with gaussian kernel and bandwidth = 2.5.
```{r}
#### Calculate all 3 density estimations ####
#Density Estimations for rho1 and rho2
rho1_VS <- 1/rowSums(Adjacency_Matrix_VS)
rho2_VS <- 1/(1 + rowSums(Adjacency_Matrix_VS^2))

kernel <- function(x, h){
  1/(2*pi*h^2) * exp(-1/2 * (x/h)^2)
}
#Calculate euclidean distance to all k-nearest neighbors (list with each gene-type in the list)
knn_distance_VS <- kNNdist(GMM_coordinates_VS, k = 1000, all = TRUE)
kde_dens_VS <- kernel(knn_distance_VS, h = 2.5) %>% 
  rowSums()
#############################################
```



Below is a method for checking the distribution of the distance from the true mode of the GMM to the estimated mode for the 3 different methods. This is done to evaluate which of the 3 density estimators best suited for our scenario. We begin by looking at the nearest neighbor of the true mode and continue outwards until a drop in density occurs and check the distance from the true mode to the point with the highest density estimation.
```{r}
gg <- cbind(1:nrow(GMM_coordinates_VS), t(dista(mu_VS, GMM_coordinates_VS)), rho1_VS, rho2_VS, kde_dens_VS)
nr_of_clusters = length(unique(GMM_data_VS$Samples))
Modes_VS1 <- matrix(NA, nrow = nr_of_clusters, ncol = 4)
Modes_VS2 <- matrix(NA, nrow = nr_of_clusters, ncol = 4)
Modes_VS3 <- matrix(NA, nrow = nr_of_clusters, ncol = 4)

tt2 <- proc.time()
for (j in 1:nr_of_clusters){
a <- cbind(1:nrow(gg), gg[order(gg[,j+1]), ])
peak1 <- a[1, 253]
peak2 <- a[1, 254]
peak3 <- a[1, 255]
H1 = 2
H2 = 2
H3 = 2
L1 = 0
L2 = 0
L3 = 0
# Find estimated modes for rho1
  while(L1 < 30){
    if (a[H1, 253] > peak1){
      peak1 <- a[H1, 253]
      L1 = 0
    }
    else {
      L1 = L1 + 1
    }
    H1 = H1 + 1
  }
 #Rho2
  while(L2 < 30){
    if (a[H2, 254] > peak2){
      peak2 <- a[H2, 254]
      L2 = 0
    }
    else {
      L2 = L2 + 1
    }
    H2 = H2 + 1
  }
 #KDE
  while(L3 < 30){
    if (a[H3, 255] > peak3){
      peak3 <- a[H3, 255]
      L3 = 0
    }
    else {
      L3 = L3 + 1
    }
    H3 = H3 + 1
  }
#KNN Index, Datapoint ID, Distance to Mode, Density
Modes_VS1[j, ] = a[H1-31, c(1, 2, j+2, 253)]
Modes_VS2[j, ] = a[H2-31, c(1, 2, j+2, 254)]
Modes_VS3[j, ] = a[H3-31, c(1, 2, j+2, 255)]
print(j)
}
```

We now construct the dataframe needed for evaluation of the three density estimators.
```{r}
Final_mode_df_VS <- Modes_VS1 %>% 
  as_tibble() %>% 
  rename(c("KNN index" = V1, "Datapoint ID" = V2, "Distance to mode" = V3, "Density" = V4)) %>% 
  mutate(Method = "Inverse Distance") %>% 
  add_row(`KNN index` = Modes_VS2[, 1], `Datapoint ID` = Modes_VS2[, 2], `Distance to mode` = Modes_VS2[, 3], `Density` = Modes_VS2[, 4], Method = "Stationary Distribution") %>% 
  add_row(`KNN index` = Modes_VS3[, 1], `Datapoint ID` = Modes_VS3[, 2], `Distance to mode` = Modes_VS3[, 3], `Density` = Modes_VS3[, 4], Method = "KDE") 

#saveRDS(Final_mode_df_VS, file = "Estimated_Modes_VS.rdata")

Estimated_vs_True_VS <- readRDS("Estimated_Modes_VS.rdata")

Estimated_Mode_Statistics_VS <- Estimated_vs_True_VS %>% 
    mutate(ID = rep(1:nr_of_clusters, 3)) %>% 
  mutate(x = GMM_coordinates_VS[`Datapoint ID`, 1],
         y = GMM_coordinates_VS[`Datapoint ID`, 2],
         mu_x = rep(mu_VS[, 1], 3),
         mu_y = rep(mu_VS[, 2], 3)) %>% 
  mutate(diff_x = x-mu_x,
         diff_y = y-mu_y)

# All points around the second peak of KDE
Far_distance_VS <- Estimated_vs_True_VS %>% 
  mutate(ID = rep(1:nr_of_clusters, 3)) %>% 
  filter(`Distance to mode` > 2.3) 
```

All above is ground work
----------------------------------------------------------------------------------------
All Below is Analysis



THe KDE method performs worse than the KNN methods. The KDE find the peak far away from the true cluster center in several cases as can be seen in the distribution of the distance to the true mode below.
```{r}
#Spatial distribution of estimated modes  
Estimated_vs_True_VS %>% 
  ggplot(aes(x = `KNN index`, col = `Method`)) +
  geom_density() +
  labs(title = "Distribution of which k-NN of true mode is the estimated mode")

#Shows distribution of the distance of estimated mode to the true mode
Estimated_vs_True_VS %>% 
  ggplot(aes(x = `Distance to mode`, col = Method)) +
  geom_density() +
  labs(title = "Distribution of distance to true mode")
ggsave("1 Distribution of Distance to True Mode.png")


mean_sd_above_distribution_VS <- Estimated_vs_True_VS %>% 
  group_by(Method) %>% 
  summarise(mean = mean(`Distance to mode`),
            sd = sd(`Distance to mode`))
```

RGB Plot + bias/variance of spatial
```{r}
# How does estimated modes lie from the perspective of the true modes?
ggplot(Estimated_Mode_Statistics_VS, aes(x = diff_x, y = diff_y, col = Method)) +
  geom_point() +
  labs(title = "Estimated modes position from the perspective of true modes")
ggsave("3 RGB plot.png")
ggplot(Estimated_Mode_Statistics_VS, aes(x = diff_x, y = diff_y)) +
  geom_point() +
  facet_grid(~Method)

#Table of bias and standard deviation
Estimated_Mode_Statistics_VS %>% 
  group_by(Method) %>% 
  summarise(x_bias = mean(diff_x), y_bias = mean(diff_y), x_sd = sd(diff_x), y_sd = sd(diff_y))
```